---
title: "HW5"
author: "Bohan Zhu"
date: "2025-11-18"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
```

```{r}
library(tidyverse)
library(p8105.datasets)
library(modelr)
```

```{r,include=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
  fig.retina = 2,
  dpi = 320
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
set.seed(1)
```

## Problem 1

```{r}
homicides = 
  read_csv("data/homicide-data.csv", 
           na = c("NA",".","","Unknown")) |>
  janitor::clean_names() 

homicide_df = 
  homicides |> 
  mutate(
    city_state = str_c(city, ", ", state),
    status = ifelse(disposition == "Closed by arrest", 1, 0)
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race == "White" | victim_race == "Black"
  )
```

```{r}
baltimore_df <- homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  select(status, victim_age, victim_race, victim_sex)
```

```{r}
fit_logistic = 
  baltimore_df |> 
  glm(status ~ victim_age + victim_race + victim_sex, data = _, 
      family = binomial())

fit_logistic |> 
  broom::tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  select(estimate, conf.low, conf.high) |> 
  knitr::kable(digits = 3)
```

```{r}
fit_city_glm = function(df) {
  glm(status ~ victim_age + victim_race + victim_sex,
      data = df, family = binomial())
}

city_or_df =
  homicide_df |>
  nest(data = -city_state) |> 
  mutate(
    fits = map(data, fit_city_glm),
    results = map(fits, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |>
  unnest(results) |>
  filter(term == "victim_sexMale") |>
  select(city_state, estimate, conf.low, conf.high)

city_or_df
```

```{r}
city_or_df |> 
  mutate(
    city_state = fct_reorder(city_state, estimate)
    ) |>
  ggplot(aes( x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(size = 5,angle = 90,hjust = 1)) +
  ggtitle("Odds Ratio for solved homicides among sex")
```

The plot shows substantial variation across cities in the adjusted odds ratios comparing homicide clearance for male versus female victims. In most cities, the estimated OR is below 1, suggesting that cases involving male victims are less likely to be solved than those involving female victims after adjusting for age and race. However, a few cities exhibit ORs above 1, indicating higher clearance odds for male victims. Several cities have wide confidence intervals, particularly where the ORs are extreme, reflecting greater uncertainty and likely smaller sample sizes.

## Problem 2

```{r}
data("weather_df")

weather_df |> 
  select(tmax, tmin, prcp) |> 
  drop_na()
```

```{r}
weather_bootstrap_results = 
  weather_df |> 
  bootstrap(n = 5000) |> 
  mutate(
    df = map(strap, as_tibble),
    fits = map(df, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results_r2 = map(fits, broom::glance),
    results_coef = map(fits, broom::tidy)
  ) |> 
  select(.id, results_r2, results_coef)
```

First, let's look at the distribution of $r^2$. 

```{r}
r2_dist =
  weather_bootstrap_results |> 
  unnest(results_r2) |> 
  select(.id, r.squared) 

r2_dist |> 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(title = "Bootstrap distribution of R^2",
       x = "R^2")
```

The bootstrap distribution of $R^2$is unimodal and approximately symmetric, with most values concentrated around 0.94, indicating a strong fit of the model. The $95\%$ bootstrap confidence interval for $R^2$ ranges from 0.934 to 0.947, suggesting that the proportion of variability in daily maximum temperature explained by minimum temperature and precipitation is consistently high across resamples.

Then, look at the confidence interval for $r^2$

```{r}
r2_dist |> 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)
  ) |> knitr::kable(digits = 3)
```

Similarly, we can look at the distribution of $\frac{\hat{\beta_{1}}}{\hat{\beta_{2}}}$

```{r}
coef_dist =
  weather_bootstrap_results |> 
  unnest(results_coef) |> 
  filter(term %in% c("tmin", "prcp")) |> 
  select(.id, term, estimate) |> 
  pivot_wider(names_from = term, values_from = estimate) |> 
  mutate(beta_ratio = tmin / prcp)

coef_dist |> 
  ggplot(aes(x = beta_ratio)) +
  geom_density() +
  labs(title = "Bootstrap distribution of beta1 / beta2",
       x = "beta1 / beta2")
```

The bootstrap distribution of $\frac{\hat{\beta_{1}}}{\hat{\beta_{2}}}$ is unimodal but clearly skewed, with all values being negative. This indicates that the effects of minimum temperature and precipitation on maximum temperature have opposite signs and differ substantially in magnitude. The $95\%$ bootstrap confidence interval for $\frac{\hat{\beta_{1}}}{\hat{\beta_{2}}}$ ranges from −279.7 to −125.7, suggesting that this ratio is consistently negative across bootstrap samples.

We may also look at the confidence interval for $\frac{\hat{\beta_{1}}}{\hat{\beta_{2}}}$.

```{r}
coef_dist |> 
  summarize(
    ci_lower = quantile(beta_ratio, 0.025),
    ci_upper = quantile(beta_ratio, 0.975)
  ) |> knitr::kable(digits = 3)
```

## Problem 3

```{r}
birthweight_df = 
  read_csv("data/birthweight.csv",
           na = c("NA",".","")) |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(babysex, 
                     levels = c(1, 2),
                     labels = c("male", "female")),
    
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("white", "black", "asian",
                              "puerto rican","other","unknown")),
    
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("white", "black", "asian",
                              "puerto rican", "other")),
    malform = factor(malform,
                   levels = c(0, 1),
                   labels = c("absent", "present"))
  )

anyNA(birthweight_df)
```

I chose these variables to build a more balanced model by covering different factors that affect birthweight. `wtgain` and `ppbmi` represent the mother’s health and nutrition. `smoken` reflects pregnancy behaviors. `fincome` and `mrace` capture social and demographic differences. `parity` adds information about the mother’s pregnancy history. Together, these variables give a more complete view instead of focusing on only one type of factor.


```{r}
model_1 = lm(bwt ~ wtgain + ppbmi + smoken + fincome + mrace + parity, 
             data = birthweight_df)

model_1 |> 
  broom::tidy() |> 
  select(term,estimate,p.value) |> 
  knitr::kable(digits = 4)
```

`wtgain`, `ppbmi`, `smoken`, `fincome`, and `mrace` show strong and meaningful associations with birthweight in the expected directions. Greater maternal weight gain and higher pre-pregnancy BMI are linked to higher birthweight, while smoking is associated with a substantial decrease. Higher family income also predicts slightly higher birthweight. Compared to white mothers, Black and Puerto Rican mothers tend to have lower-weight births. `parity` and Asian race are not statistically significant in this model. Overall, the results align with known maternal, socioeconomic, and behavioral influences on birthweight.

```{r}
birthweight_df |> 
  select(bwt, wtgain, ppbmi, smoken, fincome, mrace, parity) |> 
  modelr::add_residuals(model_1) |> 
  modelr::add_predictions(model_1) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Residuals vs Fitted plot", x = 
         "predicted value based on my model")
```

The residuals are roughly centered around zero with no strong pattern, suggesting that the linearity assumption is reasonable. However, the spread of residuals increases slightly at higher fitted values, indicating some mild heteroscedasticity. Overall, the model fits reasonably well but is not perfect.

```{r}
model_2 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
model_3 = lm(bwt ~ bhead * blength * babysex, data = birthweight_df)
```

```{r}
cv_df = 
  crossv_mc(birthweight_df, n = 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

```{r}
cv_df = 
  cv_df |> 
  mutate(
    model_1 = map(train, \(df) lm(bwt ~ wtgain + ppbmi + smoken + fincome + 
                                    mrace + parity, data = df)),
    model_2 = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_3 = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))
  ) |> 
  mutate(
    rmse_model_1 = map2_dbl(model_1, test, rmse),
    rmse_model_2 = map2_dbl(model_2, test, rmse),
    rmse_model_3= map2_dbl(model_3, test, rmse),
  )
```

```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  ggplot(aes(x = model, y = rmse,fill = model)) +
  geom_violin()
```

Model 3 shows the lowest RMSE across the Monte-Carlo cross-validation replicates, indicating the best predictive performance. Model 2 performs moderately well, while Model 1 has the highest and most variable RMSE, suggesting weaker predictive ability. Overall, Model 3 provides the most accurate predictions of birthweight among the three models.